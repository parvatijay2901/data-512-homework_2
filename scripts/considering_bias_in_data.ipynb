{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data 512: Homework #2 (Considering Bias in Data)\n",
    "In this homework, we aim to analyze the coverage and quality of Wikipedia articles related to political figures across different countries. By combining datasets of Wikipedia articles with country population data, we can examine how the representation of politicians varies among nations and how this may reflect underlying biases in data collection and presentation.\n",
    "\n",
    "In this homework, we will work with two datasets,\n",
    "- **Politicians by Country Dataset**: `politicians_by_country.AUG.2024.csv` contains a list of Wikipedia articles about politicians categorized by their nationality.\n",
    "- **Population Dataset**: `population_by_country_AUG.2024.csv` includes population data for various countries, sourced from the Population Reference Bureau.\n",
    "\n",
    "We have 2 main sub-sections here, (1) Data Acquisition, (2) Data Analysis/Results, but before getting into it, let us import the required libraries.\n",
    "\n",
    "### Import required libraries and constants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/parvati/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# These are standard python modules\n",
    "import json, time\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# The module mentioned below are not a standard Python module. You will need to install this with pip/pip3 if you do not already have it\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# We have a few user defined scripts, we call the method to another script this way\n",
    "from apikeys.KeyManager import KeyManager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Data Acquisition\n",
    "\n",
    "In this sub-section, we mainly have 4 main sections,\n",
    "- We will take the raw input data and make sure it’s clean and organized the way we need it; mainly we’ll remove any duplicates and irrelevent or missing entries, focus on including the `pageid` and `current revision id` for each politician's article and have the dataset ready for the next step. \n",
    "- We will get the predicted quality scores for each article in the Wikipedia dataset using a machine learning system called ORES (Objective Revision Evaluation Service), which classifies articles into quality categories ranging from Featured Article (FA) to Stub (Stub). We will read each line from the `revised_politicians_by_country_with_pageinfo_AUG.2024.csv` file, make a request to get the current revision ID of the article page, and then use that information to request a quality score from ORES. Additionally, we will calculate and print the error rate, which is the number of articles without a score divided by the total number of articles.\n",
    "- We will merge the Wikipedia politicians articles dataset (generated in the previous step) with population data using country names in this step. , List of unmatched countries are saved in `wp_countries-no_match.txt` and data with countries having successful matches are stored in a CSV file, `wp_politicians_by_country.csv`.\n",
    "- We have to calculate the total articles per capita and high-quality articles per capita (for \"FA\" or \"GA\" articles) on both a country and regional basis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define CONSTANTS in the next step to make the code more readable (avoided hardcoding values), maintainable (all the quick updates in a single place), and easy to update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The basic English Wikipedia API endpoint\n",
    "API_ENWIKIPEDIA_ENDPOINT = \"https://en.wikipedia.org/w/api.php\"\n",
    "API_HEADER_AGENT = 'User-Agent'\n",
    "\n",
    "# We'll assume that there needs to be some throttling for these requests - we should always be nice to a free data resource\n",
    "API_LATENCY_ASSUMED = 0.002       # Assuming roughly 2ms latency on the API and network\n",
    "API_THROTTLE_WAIT = (1.0/100.0)-API_LATENCY_ASSUMED\n",
    "\n",
    "# When making automated requests we should include something that is unique to the person making the request\n",
    "# This should include an email - your UW email would be good to put in there\n",
    "REQUEST_HEADERS = {'User-Agent': '<pj2901@uw.edu>, University of Washington, MSDS DATA 512 - AUTUMN 2024'}\n",
    "\n",
    "# Get the list of articles to be crawled\n",
    "ARTICLE_TITLES = \"\" # This will be modified in the later part of this notebook\n",
    "\n",
    "# This is a string of additional page properties that can be returned see the Info documentation for\n",
    "# what can be included. If you don't want any this can simply be the empty string\n",
    "PAGEINFO_EXTENDED_PROPERTIES = \"\"\n",
    "\n",
    "# This template lists the basic parameters for making this\n",
    "PAGEINFO_PARAMS_TEMPLATE = {\n",
    "    \"action\": \"query\",\n",
    "    \"format\": \"json\",\n",
    "    \"titles\": \"\",           # to simplify this should be a single page title at a time\n",
    "    \"prop\": \"info\",\n",
    "    \"inprop\": PAGEINFO_EXTENDED_PROPERTIES\n",
    "}\n",
    "\n",
    "# The current LiftWing ORES API endpoint and prediction model\n",
    "API_ORES_LIFTWING_ENDPOINT = \"https://api.wikimedia.org/service/lw/inference/v1/models/{model_name}:predict\"\n",
    "API_ORES_EN_QUALITY_MODEL = \"enwiki-articlequality\"\n",
    "\n",
    "# The throttling rate is a function of the Access token that you are granted when you request the token. The constants\n",
    "# come from dissecting the token and getting the rate limits from the granted token. An example of that is below.\n",
    "API_LATENCY_ASSUMED = 0.002       # Assuming roughly 2ms latency on the API and network\n",
    "API_THROTTLE_WAIT = ((60.0*60.0)/5000.0)-API_LATENCY_ASSUMED  # The key authorizes 5000 requests per hour\n",
    "\n",
    "# When making automated requests we should include something that is unique to the person making the request\n",
    "# This should include an email - your UW email would be good to put in there\n",
    "# Because all LiftWing API requests require some form of authentication, you need to provide your access token\n",
    "# as part of the header too\n",
    "REQUEST_HEADER_TEMPLATE = {\n",
    "    'User-Agent': \"<{email_address}>, University of Washington, MSDS DATA 512 - AUTUMN 2024\",\n",
    "    'Content-Type': 'application/json',\n",
    "    'Authorization': \"Bearer {access_token}\"\n",
    "}\n",
    "\n",
    "# This is a template for the parameters that we need to supply in the headers of an API request\n",
    "REQUEST_HEADER_PARAMS_TEMPLATE = {\n",
    "    'email_address' : \"\",         # your email address should go here\n",
    "    'access_token'  : \"\"          # the access token you create will need to go here\n",
    "}\n",
    "\n",
    "# A dictionary of English Wikipedia article titles (keys) and sample revision IDs that can be used for this ORES scoring - this variable will be modified later in the notebook\n",
    "ARTICLE_REVISIONS = {}\n",
    "\n",
    "# This is a template of the data required as a payload when making a scoring request of the ORES model\n",
    "ORES_REQUEST_DATA_TEMPLATE = {\n",
    "    \"lang\":        \"en\",     # required that its english - we're scoring English Wikipedia revisions\n",
    "    \"rev_id\":      \"\",       # this request requires a revision id\n",
    "    \"features\":    True\n",
    "}\n",
    "\n",
    "# These are used later - defined here so they, at least, have empty values\n",
    "USERNAME = \"\"\n",
    "ACCESS_TOKEN = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Define functions\n",
    "\n",
    "In this section, we will define all the functions we need in this notebook. Having functions make it easier to read, reuse, and maintain throughout the notebook.\n",
    "\n",
    "#### 1.1.1 Request data from an article page\n",
    "\n",
    "We access the page info data using the [MediaWiki REST API for the EN Wikipedia](https://www.mediawiki.org/wiki/API:Main_page). The MediaWiki Action API is a web service that allows access to some wiki features like authentication, page operations, and search. It can provide meta information about the wiki and the logged-in user.\n",
    "\n",
    "We request the summary 'page info' for a single article page in the below method. We send an HTTP GET request to the Wikipedia API endpoint that returns the metadata about the specified article.\n",
    "\n",
    "The API documentation, [API:Info](https://www.mediawiki.org/wiki/API:Info), covers additional details and can be referred if required.\n",
    "\n",
    "**License:** This code example was developed by Dr. David W. McDonald for use in DATA 512, a course in the UW MS Data Science degree program. This code is provided under the [Creative Commons](https://creativecommons.org) [CC-BY license](https://creativecommons.org/licenses/by/4.0/). Revision 1.2 - September 16, 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_pageinfo_per_article(article_title = None, \n",
    "                                 endpoint_url = API_ENWIKIPEDIA_ENDPOINT, \n",
    "                                 request_template = PAGEINFO_PARAMS_TEMPLATE,\n",
    "                                 headers = REQUEST_HEADERS):\n",
    "    \n",
    "    # article title can be as a parameter to the call or in the request_template\n",
    "    if article_title:\n",
    "        request_template['titles'] = article_title\n",
    "\n",
    "    if not request_template['titles']:\n",
    "        raise Exception(\"Must supply an article title to make a pageinfo request.\")\n",
    "\n",
    "    if API_HEADER_AGENT not in headers:\n",
    "        raise Exception(f\"The header data should include a '{API_HEADER_AGENT}' field that contains your UW email address.\")\n",
    "\n",
    "    if 'uwnetid@uw' in headers[API_HEADER_AGENT]:\n",
    "        raise Exception(f\"Use your UW email address in the '{API_HEADER_AGENT}' field.\")\n",
    "\n",
    "    # make the request\n",
    "    try:\n",
    "        # we'll wait first, to make sure we don't exceed the limit in the situation where an exception\n",
    "        # occurs during the request processing - throttling is always a good practice with a free\n",
    "        # data source like Wikipedia - or any other community sources\n",
    "        if API_THROTTLE_WAIT > 0.0:\n",
    "            time.sleep(API_THROTTLE_WAIT)\n",
    "        response = requests.get(endpoint_url, headers=headers, params=request_template)\n",
    "        json_response = response.json()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        json_response = None\n",
    "    return json_response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.2 Request data from a chunk of articles\n",
    "\n",
    "In the function defined below, we get Wikipedia page information for a list of article titles in chunks. We process the list of article titles in smaller batches to avoid exceeding API request limits. We send requests to the Wikipedia API for each chunk and get the page metadata including the page ID and current revision ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_pageinfo_for_chunks(article_titles, chunk_size=50):\n",
    "    \n",
    "    requested_info = []\n",
    "\n",
    "    # Iterate through the article titles in chunks\n",
    "    for i in range(0, len(article_titles), chunk_size):\n",
    "        chunk = article_titles[i:i + chunk_size]    # Get a chunk of titles\n",
    "        page_titles = '|'.join(chunk)  # Create a pipe-separated string\n",
    "        print(f\"Getting page info data for: {page_titles}...\")\n",
    "\n",
    "        # Prepare the request info\n",
    "        request_info = PAGEINFO_PARAMS_TEMPLATE.copy()\n",
    "        request_info['titles'] = page_titles\n",
    "\n",
    "        # Fetch page info\n",
    "        info = request_pageinfo_per_article(request_template=request_info)\n",
    "\n",
    "        # Process the response and append to results\n",
    "        if 'query' in info and 'pages' in info['query']:\n",
    "            for page in info['query']['pages'].values():\n",
    "                # Save only pageid and lastrevid\n",
    "                filtered_info = {\n",
    "                    'title': page.get('title'),\n",
    "                    'pageid': page.get('pageid'),\n",
    "                    'lastrevid': page.get('lastrevid')\n",
    "                }\n",
    "                requested_info.append(filtered_info)  # Add the filtered info to results\n",
    "        else:\n",
    "            print(\"No data found for this chunk.\")\n",
    "\n",
    "    return requested_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.3 Make the ORES API request\n",
    "\n",
    "The API request will be made using a function to encapsulate call and make access reusable in other notebooks. The procedure is parameterized, relying on the constants above for some important default parameters. The primary assumption is that this function will be used to request data for a set of article revisions. The main parameter is `article_revid`. One should be able to simply pass in a new article revision id on each call and get back a python dictionary as the result. A valid result will be a dictionary that contains the probabilities that the specific revision is one of six different article quality levels. Generally, quality level with the highest probability score is considered the quality level for the article. This can be tricky when you have two (or more) highly probable quality levels.\n",
    "\n",
    "**License:** This code example was developed by Dr. David W. McDonald for use in DATA 512, a course in the UW MS Data Science degree program. This code is provided under the [Creative Commons](https://creativecommons.org) [CC-BY license](https://creativecommons.org/licenses/by/4.0/). Revision 1.2 - September 16, 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_ores_score_per_article(article_revid = None, email_address=None, access_token=None,\n",
    "                                   endpoint_url = API_ORES_LIFTWING_ENDPOINT, \n",
    "                                   model_name = API_ORES_EN_QUALITY_MODEL, \n",
    "                                   request_data = ORES_REQUEST_DATA_TEMPLATE, \n",
    "                                   header_format = REQUEST_HEADER_TEMPLATE, \n",
    "                                   header_params = REQUEST_HEADER_PARAMS_TEMPLATE):\n",
    "    \n",
    "    #    Make sure we have an article revision id, email and token\n",
    "    #    This approach prioritizes the parameters passed in when making the call\n",
    "    if article_revid:\n",
    "        request_data['rev_id'] = article_revid\n",
    "    if email_address:\n",
    "        header_params['email_address'] = email_address\n",
    "    if access_token:\n",
    "        header_params['access_token'] = access_token\n",
    "    \n",
    "    #   Making a request requires a revision id - an email address - and the access token\n",
    "    if not request_data['rev_id']:\n",
    "        raise Exception(\"Must provide an article revision id (rev_id) to score articles\")\n",
    "    if not header_params['email_address']:\n",
    "        raise Exception(\"Must provide an 'email_address' value\")\n",
    "    if not header_params['access_token']:\n",
    "        raise Exception(\"Must provide an 'access_token' value\")\n",
    "    \n",
    "    # Create the request URL with the specified model parameter - default is a article quality score request\n",
    "    request_url = endpoint_url.format(model_name=model_name)\n",
    "    \n",
    "    # Create a compliant request header from the template and the supplied parameters\n",
    "    headers = dict()\n",
    "    for key in header_format.keys():\n",
    "        headers[str(key)] = header_format[key].format(**header_params)\n",
    "    \n",
    "    # make the request\n",
    "    try:\n",
    "        # we'll wait first, to make sure we don't exceed the limit in the situation where an exception\n",
    "        # occurs during the request processing - throttling is always a good practice with a free data\n",
    "        # source like ORES - or other community sources\n",
    "        if API_THROTTLE_WAIT > 0.0:\n",
    "            time.sleep(API_THROTTLE_WAIT)\n",
    "        #response = requests.get(request_url, headers=headers)\n",
    "        response = requests.post(request_url, headers=headers, data=json.dumps(request_data))\n",
    "        json_response = response.json()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        json_response = None\n",
    "    return json_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.4 Extract Score details\n",
    "When the LiftWing ML Service API makes a request to get the ORES score, we obtain a lot of information. We don't want all of them. The below function, extracts and saves the obtained quality prediction and probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_score_details(article_title, revision_id, score):\n",
    "    # extract quality prediction and probabilities\n",
    "    score_details = score[\"enwiki\"][\"scores\"].get(str(revision_id), {}).get(\"articlequality\", {}).get(\"score\", {})\n",
    "    quality_prediction = score_details.get(\"prediction\", \"\")\n",
    "    probabilities = score_details.get(\"probability\", {})\n",
    "    \n",
    "    # Hold the score data in this dictionary\n",
    "    score_dict = {\n",
    "        'article_title': article_title,\n",
    "        'revision_id': revision_id,\n",
    "        'quality_prediction': quality_prediction\n",
    "    }\n",
    "    \n",
    "    # Add probabilities to the score data\n",
    "    score_dict.update({f'Probability {key}': value for key, value in probabilities.items()})\n",
    "\n",
    "    return score_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Load the Politicians by Country Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>url</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Majah Ha Adrif</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Majah_Ha_Adrif</td>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Haroon al-Afghani</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Haroon_al-Afghani</td>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tayyab Agha</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Tayyab_Agha</td>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Khadija Zahra Ahmadi</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Khadija_Zahra_Ah...</td>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aziza Ahmadyar</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Aziza_Ahmadyar</td>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name                                                url  \\\n",
       "0        Majah Ha Adrif       https://en.wikipedia.org/wiki/Majah_Ha_Adrif   \n",
       "1     Haroon al-Afghani    https://en.wikipedia.org/wiki/Haroon_al-Afghani   \n",
       "2           Tayyab Agha          https://en.wikipedia.org/wiki/Tayyab_Agha   \n",
       "3  Khadija Zahra Ahmadi  https://en.wikipedia.org/wiki/Khadija_Zahra_Ah...   \n",
       "4        Aziza Ahmadyar       https://en.wikipedia.org/wiki/Aziza_Ahmadyar   \n",
       "\n",
       "       country  \n",
       "0  Afghanistan  \n",
       "1  Afghanistan  \n",
       "2  Afghanistan  \n",
       "3  Afghanistan  \n",
       "4  Afghanistan  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "politicians_df = pd.read_csv('../data/input_data/politicians_by_country_AUG.2024.csv')\n",
    "politicians_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1 Data Quality Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let us check if there are any missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name       0\n",
       "url        0\n",
       "country    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "politicians_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no missing values!\n",
    "\n",
    "Now let us see if there are any duplicate values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " # Duplicate values in the dataframe:  0\n",
      " # Duplicate values in the dataframe (with same article name):  41\n"
     ]
    }
   ],
   "source": [
    "print(\" # Duplicate values in the dataframe: \", len(politicians_df[politicians_df.duplicated()]))\n",
    "\n",
    "politicians_name_counts = politicians_df['name'].value_counts()\n",
    "duplicate_politicians_names = politicians_name_counts[politicians_name_counts  > 1]\n",
    "print(\" # Duplicate values in the dataframe (with same article name): \", len(duplicate_politicians_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like there are 41 politicians with multiple entries, let us observe then in detail to understand why there are duplicates in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>url</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3451</th>\n",
       "      <td>Torokul Dzhanuzakov</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Torokul_Dzhanuzakov</td>\n",
       "      <td>Kazakhstan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3704</th>\n",
       "      <td>Torokul Dzhanuzakov</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Torokul_Dzhanuzakov</td>\n",
       "      <td>Kyrgyzstan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6504</th>\n",
       "      <td>Torokul Dzhanuzakov</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Torokul_Dzhanuzakov</td>\n",
       "      <td>Tajikistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6937</th>\n",
       "      <td>Torokul Dzhanuzakov</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Torokul_Dzhanuzakov</td>\n",
       "      <td>Uzbekistan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     name                                                url  \\\n",
       "3451  Torokul Dzhanuzakov  https://en.wikipedia.org/wiki/Torokul_Dzhanuzakov   \n",
       "3704  Torokul Dzhanuzakov  https://en.wikipedia.org/wiki/Torokul_Dzhanuzakov   \n",
       "6504  Torokul Dzhanuzakov  https://en.wikipedia.org/wiki/Torokul_Dzhanuzakov   \n",
       "6937  Torokul Dzhanuzakov  https://en.wikipedia.org/wiki/Torokul_Dzhanuzakov   \n",
       "\n",
       "         country  \n",
       "3451  Kazakhstan  \n",
       "3704  Kyrgyzstan  \n",
       "6504  Tajikistan  \n",
       "6937  Uzbekistan  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "duplicate_politicians_names_list = duplicate_politicians_names.index.tolist()\n",
    "for name in duplicate_politicians_names_list:\n",
    "    subset_politicians_df = politicians_df[politicians_df['name'] == name]\n",
    "    display(subset_politicians_df)\n",
    "    break # Remove to see all the duplicate entries in detail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that for a single name and url, there are different countries. One possible reason could be that a few individuals are recognized as a politician in multiple countries and may have multiple affiliations different from their original nationality.\n",
    "\n",
    "To solve the issue, I manually looked into the backgrounds of all the 41 politicians and decided to only have the row which specifically mentions the country of nationaility of that politicians. All the other rows are dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>url</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Majah Ha Adrif</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Majah_Ha_Adrif</td>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Haroon al-Afghani</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Haroon_al-Afghani</td>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tayyab Agha</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Tayyab_Agha</td>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Khadija Zahra Ahmadi</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Khadija_Zahra_Ah...</td>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aziza Ahmadyar</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Aziza_Ahmadyar</td>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name                                                url  \\\n",
       "0        Majah Ha Adrif       https://en.wikipedia.org/wiki/Majah_Ha_Adrif   \n",
       "1     Haroon al-Afghani    https://en.wikipedia.org/wiki/Haroon_al-Afghani   \n",
       "2           Tayyab Agha          https://en.wikipedia.org/wiki/Tayyab_Agha   \n",
       "3  Khadija Zahra Ahmadi  https://en.wikipedia.org/wiki/Khadija_Zahra_Ah...   \n",
       "4        Aziza Ahmadyar       https://en.wikipedia.org/wiki/Aziza_Ahmadyar   \n",
       "\n",
       "       country  \n",
       "0  Afghanistan  \n",
       "1  Afghanistan  \n",
       "2  Afghanistan  \n",
       "3  Afghanistan  \n",
       "4  Afghanistan  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes_to_delete = [3451, 6504, 6937, 739, 3864, 4780, 3168, 438, 5725, 5518, 151, 5561, 1758, 5546, 6059, 424, 5443, 6134, 3293, 4773, 6591, 2596, 6815, 6254, 6123, 733, 3093, 1903, 6351, 5576, 2869, 6482, 5374, 6267, 5513, 5534, 5632, 2664, 1119, 2113, 6285, 6356, 4853, 6266]\n",
    "revised_politicians_df = politicians_df.drop(indexes_to_delete) # drop the indexes that's not of the politicians nationality\n",
    "revised_politicians_df.to_csv(\"../data/generated_intermediate_data/revised_politicians_by_country_AUG.2024.csv\") # save the dataset for quick reference / to be used in further analysis\n",
    "revised_politicians_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to make sure that we don't have any more duplicate name entries, let's execte the step below,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " # Duplicate values in the dataframe (with same article name):  0\n"
     ]
    }
   ],
   "source": [
    "politicians_name_counts = revised_politicians_df['name'].value_counts()\n",
    "duplicate_politicians_names = politicians_name_counts[politicians_name_counts  > 1]\n",
    "print(\" # Duplicate values in the dataframe (with same article name): \", len(duplicate_politicians_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Get required Wikipedia page information for the articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For further analysis, we need the `last revision id` and `page id` for each of the politician articles. As mentioned in the section where we defined the method `request_pageinfo_per_article`, we will use the MediaWiki REST API to get these required page information. \n",
    "\n",
    "To parallely to get the information for multiple pages at the same time, we have defined `request_pageinfo_for_chunks` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us first update the ARTICLE_TITLES constant with the revised names of politicians.\n",
    "ARTICLE_TITLES = revised_politicians_df['name'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully fetched all the additional page info!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>pageid</th>\n",
       "      <th>lastrevid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abdul Baqi Turkistani</td>\n",
       "      <td>27428272.0</td>\n",
       "      <td>1.231655e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abdul Ghani Ghani</td>\n",
       "      <td>29443640.0</td>\n",
       "      <td>1.227026e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abdul Rahim Ayoubi</td>\n",
       "      <td>44482763.0</td>\n",
       "      <td>1.226326e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ahmad Wali Massoud</td>\n",
       "      <td>34682634.0</td>\n",
       "      <td>1.221721e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aimal Faizi</td>\n",
       "      <td>52438668.0</td>\n",
       "      <td>1.185106e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   title      pageid     lastrevid\n",
       "0  Abdul Baqi Turkistani  27428272.0  1.231655e+09\n",
       "1      Abdul Ghani Ghani  29443640.0  1.227026e+09\n",
       "2     Abdul Rahim Ayoubi  44482763.0  1.226326e+09\n",
       "3     Ahmad Wali Massoud  34682634.0  1.221721e+09\n",
       "4            Aimal Faizi  52438668.0  1.185106e+09"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetch page info for the titles and have it in a dataframe\n",
    "wiki_politicians_info = request_pageinfo_for_chunks(ARTICLE_TITLES, chunk_size=50)\n",
    "wiki_politicians_info_df = pd.DataFrame(wiki_politicians_info)\n",
    "\n",
    "clear_output(wait=True) # Cleared the cell output to save some space before uploading to github and for better clarity\n",
    "\n",
    "print(\"Successfully fetched all the additional page info!\")\n",
    "wiki_politicians_info_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The assignment instructions clearly asked us to have revision ids for the articles we just queried. Let us check that,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>pageid</th>\n",
       "      <th>lastrevid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>Barbara Eibinger-Miedl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>Mehrali Gasimov</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1150</th>\n",
       "      <td>Kyaw Myint</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1300</th>\n",
       "      <td>André Ngongang Ouandji</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900</th>\n",
       "      <td>Tomás Pimentel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2400</th>\n",
       "      <td>Richard Sumah</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4450</th>\n",
       "      <td>Segun ''Aeroland'' Adewale</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5650</th>\n",
       "      <td>Bashir Bililiqo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           title  pageid  lastrevid\n",
       "400       Barbara Eibinger-Miedl     NaN        NaN\n",
       "500              Mehrali Gasimov     NaN        NaN\n",
       "1150                  Kyaw Myint     NaN        NaN\n",
       "1300      André Ngongang Ouandji     NaN        NaN\n",
       "1900              Tomás Pimentel     NaN        NaN\n",
       "2400               Richard Sumah     NaN        NaN\n",
       "4450  Segun ''Aeroland'' Adewale     NaN        NaN\n",
       "5650             Bashir Bililiqo     NaN        NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "empty_revid_df = wiki_politicians_info_df[wiki_politicians_info_df['lastrevid'].isnull()]\n",
    "display(empty_revid_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems there was an issue with eight politicians' articles. Upon digging deep into it, I found that:\n",
    "- Mehrali Gasimov and Richard Sumah did not have any associated Wikipedia articles.\n",
    "- Other politicians had Wikipedia articles linked to them; however, these articles were not in English. The MediaWiki REST API call we made specifically searches through only English articles.\n",
    "\n",
    "One alternative that I could think of was to remove Mehrali Gasimov's and Richard Sumah's title from the dataset and feed in the right `pageid`, and `lastrevid` for other politicians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually update the politians' info that were in different languages\n",
    "wiki_politicians_info_df.loc[400] = {'title': 'Barbara Eibinger-Miedl', 'pageid': 4534118, 'lastrevid': 247199899} # 'fullurl': \"https://de.wikipedia.org/wiki/Barbara_Eibinger-Mied\"\n",
    "wiki_politicians_info_df.loc[1150] = {'title': 'Kyaw Myint', 'pageid': 69195914, 'lastrevid': 1177243609} # 'fullurl': \"https://en.wikipedia.org/wiki/Michael_Kyaw_Myint\"\n",
    "wiki_politicians_info_df.loc[1300] = {'title': 'André Ngongang Ouandji', 'pageid': 7152978, 'lastrevid': 210595074} # 'fullurl': \"https://fr.wikipedia.org/wiki/André_Ngongang_Ouandji\"\n",
    "wiki_politicians_info_df.loc[1900] = {'title': 'Tomás Pimentel', 'pageid': 9321687, 'lastrevid': 151461200} # 'fullurl': \"https://es.wikipedia.org/wiki/Tomás_Pimentel\"\n",
    "wiki_politicians_info_df.loc[4450] = {'title': \"Segun ''Aeroland'' Adewale\", 'pageid': 45496646, 'lastrevid': 1242960131} # 'fullurl': \"https://en.wikipedia.org/wiki/Segun_%22Aeroland%22_Adewale\",\n",
    "wiki_politicians_info_df.loc[5650] = {'title': 'Bashir Bililiqo', 'pageid': 18698, 'lastrevid': 65938} # 'fullurl': \"https://ff.wikipedia.org/wiki/Bashir_Bililiqo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>url</th>\n",
       "      <th>country</th>\n",
       "      <th>pageid</th>\n",
       "      <th>lastrevid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Majah Ha Adrif</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Majah_Ha_Adrif</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>10483286.0</td>\n",
       "      <td>1.233203e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Haroon al-Afghani</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Haroon_al-Afghani</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>11966231.0</td>\n",
       "      <td>1.230460e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tayyab Agha</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Tayyab_Agha</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>46841383.0</td>\n",
       "      <td>1.225662e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Khadija Zahra Ahmadi</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Khadija_Zahra_Ah...</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>71600382.0</td>\n",
       "      <td>1.234742e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aziza Ahmadyar</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Aziza_Ahmadyar</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>47805901.0</td>\n",
       "      <td>1.195651e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name                                                url  \\\n",
       "0        Majah Ha Adrif       https://en.wikipedia.org/wiki/Majah_Ha_Adrif   \n",
       "1     Haroon al-Afghani    https://en.wikipedia.org/wiki/Haroon_al-Afghani   \n",
       "2           Tayyab Agha          https://en.wikipedia.org/wiki/Tayyab_Agha   \n",
       "3  Khadija Zahra Ahmadi  https://en.wikipedia.org/wiki/Khadija_Zahra_Ah...   \n",
       "4        Aziza Ahmadyar       https://en.wikipedia.org/wiki/Aziza_Ahmadyar   \n",
       "\n",
       "       country      pageid     lastrevid  \n",
       "0  Afghanistan  10483286.0  1.233203e+09  \n",
       "1  Afghanistan  11966231.0  1.230460e+09  \n",
       "2  Afghanistan  46841383.0  1.225662e+09  \n",
       "3  Afghanistan  71600382.0  1.234742e+09  \n",
       "4  Afghanistan  47805901.0  1.195651e+09  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "politicians_with_pageinfo_df = pd.merge(revised_politicians_df, \n",
    "                                        wiki_politicians_info_df, \n",
    "                                        left_on='name', \n",
    "                                        right_on='title', \n",
    "                                        how='inner')\n",
    "politicians_with_pageinfo_df.drop('title', axis=1, inplace=True)\n",
    "politicians_with_pageinfo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Politicians with no lastrevid:  0\n"
     ]
    }
   ],
   "source": [
    "# remove Mehrali Gasimov's and Richard Sumah's title from the dataset\n",
    "indexes_to_delete = [513, 2418]\n",
    "revised_politicians_with_pageinfo_df = politicians_with_pageinfo_df.drop(indexes_to_delete)\n",
    "\n",
    "# Let us also make sure that we don't have any rows with missing entries\n",
    "print(\"# Politicians with no lastrevid: \", len(revised_politicians_with_pageinfo_df[revised_politicians_with_pageinfo_df['lastrevid'].isnull()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the results as a CSV for further analysis or quick reference\n",
    "revised_politicians_with_pageinfo_df.to_csv('../data/generated_intermediate_data/revised_politicians_by_country_with_pageinfo_AUG.2024.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Requesting ORES scores through LiftWing ML Service API\n",
    "\n",
    "In this section, we will get the predicted quality scores for each article in the Wikipedia dataset using a machine learning system called ORES (Objective Revision Evaluation Service). Wikimedia is implementing a new Machine Learning (ML) service infrastructure that they call [LiftWing](https://wikitech.wikimedia.org/wiki/Machine_Learning/LiftWing). Given that ORES already has several ML models that have been well used, ORES is the first set of APIs that are being moved to LiftWing.\n",
    "\n",
    "Wikimedia Foundation (WMF) is reworking access to their APIs. It is likely in the coming years that all API access will require some kind of authentication, either through a simple key/token or through some version of OAuth. For now this is still a work in progress. You can follow the progress from their [API portal](https://api.wikimedia.org/wiki/Main_Page). Another on-going change is better control over API services in situations where those services require additional computational resources, beyond simply serving the text of a web page (i.e., the text of an article). Services like ORES that require running an ML model over the text of an article page is an example of a compute intensive API service.\n",
    "\n",
    "We will now see how to generate article quality estimates for article revisions using the LiftWing version of [ORES](https://www.mediawiki.org/wiki/ORES). The [ORES API documentation](https://ores.wikimedia.org) can be accessed from the main ORES page. The [ORES LiftWing documentation](https://wikitech.wikimedia.org/wiki/Machine_Learning/LiftWing/Usage) is very thin ... even thinner than the standard ORES documentation. Further, it is clear that some parameters have been renamed (e.g., \"revid\" in the old ORES API is now \"rev_id\" in the LiftWing ORES API).\n",
    "\n",
    "We will need a Wikimedia user account to get access to Lift Wing (the ML API service). You can either [create an account or login](https://api.wikimedia.org/w/index.php?title=Special:UserLogin). If you have a Wikipedia user account - you might already have an Wikimedia account. If you are not sure try your Wikipedia username and password to check it. If you do not have a Wikimedia account you will need to create an account that you can use to get an access token.\n",
    "\n",
    "#### 1.4.1 Obtain the API key\n",
    "\n",
    "There is [a 'guide' that describes how to get authentication tokens](https://api.wikimedia.org/wiki/Authentication) - but not everything works the way it is described in that documentation. You should review that documentation and then read the rest of this comment. I created a [Personal API token](https://api.wikimedia.org/wiki/Authentication) following the documenation to create the server-side app key.\n",
    "\n",
    "A \"best practice\" for any code that requires an API key is to make sure that the key does not appear in the plain text of the code or notebook. One approach is to use a code based key manager that stores keys on your local machine. For more information on how to set up the key as an environment variable, refer [here](https://drive.google.com/file/d/15A8BNED9aJIqw_GiJPstsIuOx7U57adC/view?usp=sharing).\n",
    "\n",
    "**License:**\n",
    "The below code was developed by Dr. David W. McDonald for use in DATA 512, a course in the UW MS Data Science degree program. This code is provided under the [Creative Commons](https://creativecommons.org) [CC-BY license](https://creativecommons.org/licenses/by/4.0/). Revision 1.0 - August 15, 2023\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key Description:  Wikimedia JWT Access Token\n"
     ]
    }
   ],
   "source": [
    "# I don't want to distribute my keys with the source of the notebook, so I wrote a key manager object that helps\n",
    "# track all of my API keys - a username and domain name retrieves the key. The key manager hides the keys on disk separate\n",
    "# from the code. A common code idiom to hide API keys will use code to extract the key from an OS environment variable. \n",
    "#\n",
    "# You should be able to find a zip file containing the apikeys user module. Install this module into the folder where you keep \n",
    "# all of your user modules. This is also the folder that your PYTHONPATH variable points to.\n",
    "\n",
    "keyman = KeyManager()\n",
    "\n",
    "# This is my Wikipedia/Wikimedia username. They suggest you request your keys using your Wikipedia username, \n",
    "# so I also stored the API key using my Wikipedia username.\n",
    "USERNAME = \"Pj2901\"\n",
    "key_info = keyman.findRecord(USERNAME,API_ORES_LIFTWING_ENDPOINT)\n",
    "ACCESS_TOKEN = key_info[0]['access_token']\n",
    "print('Key Description: ', key_info[0]['description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.2 Requesting ORES scores\n",
    "\n",
    "There are many ways to make the API call, we will call the function `request_ores_score_per_article` by passing in three items, revision id, email, and access token.\n",
    "\n",
    "For easy access, let us store the required details in a dictionary and have it as a constant `ARTICLE_REVISIONS`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want it as an integer type before making having it in the dictionary\n",
    "revised_politicians_with_pageinfo_df['lastrevid'] = revised_politicians_with_pageinfo_df['lastrevid'].fillna(0).astype(int)\n",
    "\n",
    "ARTICLE_REVISIONS = dict(zip(revised_politicians_with_pageinfo_df['name'],\n",
    "                            revised_politicians_with_pageinfo_df['lastrevid']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_title</th>\n",
       "      <th>revision_id</th>\n",
       "      <th>quality_prediction</th>\n",
       "      <th>Probability B</th>\n",
       "      <th>Probability C</th>\n",
       "      <th>Probability FA</th>\n",
       "      <th>Probability GA</th>\n",
       "      <th>Probability Start</th>\n",
       "      <th>Probability Stub</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Majah Ha Adrif</td>\n",
       "      <td>1233202991</td>\n",
       "      <td>Start</td>\n",
       "      <td>0.114586</td>\n",
       "      <td>0.251813</td>\n",
       "      <td>0.006372</td>\n",
       "      <td>0.017664</td>\n",
       "      <td>0.548056</td>\n",
       "      <td>0.061509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Haroon al-Afghani</td>\n",
       "      <td>1230459615</td>\n",
       "      <td>B</td>\n",
       "      <td>0.416808</td>\n",
       "      <td>0.377938</td>\n",
       "      <td>0.057959</td>\n",
       "      <td>0.089012</td>\n",
       "      <td>0.052925</td>\n",
       "      <td>0.005359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tayyab Agha</td>\n",
       "      <td>1225661708</td>\n",
       "      <td>Start</td>\n",
       "      <td>0.082645</td>\n",
       "      <td>0.247194</td>\n",
       "      <td>0.005548</td>\n",
       "      <td>0.018469</td>\n",
       "      <td>0.594374</td>\n",
       "      <td>0.051770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Khadija Zahra Ahmadi</td>\n",
       "      <td>1234741562</td>\n",
       "      <td>Stub</td>\n",
       "      <td>0.019056</td>\n",
       "      <td>0.034997</td>\n",
       "      <td>0.003352</td>\n",
       "      <td>0.009019</td>\n",
       "      <td>0.264906</td>\n",
       "      <td>0.668670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aziza Ahmadyar</td>\n",
       "      <td>1195651393</td>\n",
       "      <td>Start</td>\n",
       "      <td>0.046899</td>\n",
       "      <td>0.098852</td>\n",
       "      <td>0.004757</td>\n",
       "      <td>0.019370</td>\n",
       "      <td>0.712785</td>\n",
       "      <td>0.117338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          article_title  revision_id quality_prediction  Probability B  \\\n",
       "0        Majah Ha Adrif   1233202991              Start       0.114586   \n",
       "1     Haroon al-Afghani   1230459615                  B       0.416808   \n",
       "2           Tayyab Agha   1225661708              Start       0.082645   \n",
       "3  Khadija Zahra Ahmadi   1234741562               Stub       0.019056   \n",
       "4        Aziza Ahmadyar   1195651393              Start       0.046899   \n",
       "\n",
       "   Probability C  Probability FA  Probability GA  Probability Start  \\\n",
       "0       0.251813        0.006372        0.017664           0.548056   \n",
       "1       0.377938        0.057959        0.089012           0.052925   \n",
       "2       0.247194        0.005548        0.018469           0.594374   \n",
       "3       0.034997        0.003352        0.009019           0.264906   \n",
       "4       0.098852        0.004757        0.019370           0.712785   \n",
       "\n",
       "   Probability Stub  \n",
       "0          0.061509  \n",
       "1          0.005359  \n",
       "2          0.051770  \n",
       "3          0.668670  \n",
       "4          0.117338  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_address = \"pj2901@uw.edu\"\n",
    "access_token = ACCESS_TOKEN \n",
    "\n",
    "score_dict_list = []\n",
    "failed_score_request_articles = []\n",
    "\n",
    "# Iterate over each article in ARTICLE_REVISIONS\n",
    "for i, (article_title, revision_id) in enumerate(ARTICLE_REVISIONS.items(), start=1):\n",
    "    print(f\"({i}/{len(ARTICLE_REVISIONS)}) | Obtaining LiftWing ORES scores for '{article_title}'...\")\n",
    "\n",
    "    # Make the ORES score request\n",
    "    score = request_ores_score_per_article(article_revid=revision_id,\n",
    "                                           email_address=email_address,\n",
    "                                           access_token=access_token)\n",
    "\n",
    "    # Extract quality prediction and probabilities if available, else, make a note of the article title\n",
    "    if score and \"enwiki\" in score and \"scores\" in score[\"enwiki\"]:\n",
    "        score_dict = extract_score_details(article_title, revision_id, score)\n",
    "        score_dict_list.append(score_dict)\n",
    "        print(\"Successfully obtained the ORES score!\")\n",
    "    else:\n",
    "        failed_score_request_articles.append(article_title)\n",
    "        print(\"Could not obtain the ORES score.\")\n",
    "    \n",
    "    clear_output(wait=True) # Cleared the cell output to save some space before uploading to github and for better clarity\n",
    "\n",
    "scores_df = pd.DataFrame(score_dict_list)\n",
    "scores_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We failed to fetch ORES scores for the following article(s):  []\n"
     ]
    }
   ],
   "source": [
    "print(\"We failed to fetch ORES scores for the following article(s): \", failed_score_request_articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of them failed! We successfully obtained the ORES scores for the relevant politician articls."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error rate is defined as the ratio of the number of articles for which we were not able to get a score divided by the total number of articles.\n",
    "- We dropped Mehrali Gasimov and Richard Sumah's requests in the previous step as there were no matching Wikipedia article.\n",
    "\n",
    "We manually dropped rows where a single politician had multiple nationalities (41 of them had this issue) and modified 6 rows that did not have a revision id (with the revision id of the non-english wikipedia page). I do not consider these as an error because we finally got the true predicted quality for them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# API requests made:  7111\n",
      "Error rate (%):  0.04218815918998734\n"
     ]
    }
   ],
   "source": [
    "print(\"# API requests made: \", len(politicians_with_pageinfo_df))\n",
    "\n",
    "error_rate = (3/len(politicians_with_pageinfo_df))*100\n",
    "print(\"Error rate (%): \", error_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error rate is way below 1%. Hence, we were successful in obtaining the ORES scores for the politicians.\n",
    "\n",
    "In the next step, we merge the dataset with the revised politicians dataset and save the output politicians dataset for further reference. It took 130mins to run through the 7111 articles and we can definately save some time by saving if we just need it for some analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the scores with the politicians dataframe\n",
    "revised_politicians_with_pageinfo_and_scores_df = revised_politicians_with_pageinfo_df.merge(scores_df, left_on='name', right_on='article_title', how='left')\n",
    "\n",
    "# Drop columns not required\n",
    "revised_politicians_with_pageinfo_and_scores_df.drop('article_title', axis=1, inplace=True) # it is repeated twice\n",
    "revised_politicians_with_pageinfo_and_scores_df.drop(columns=['Probability B', 'Probability C', 'Probability FA', \n",
    "                                                              'Probability GA', 'Probability Start', 'Probability Stub'], \n",
    "                                                              inplace=True) # I don't want to save these for my further analysis\n",
    "\n",
    "\n",
    "# Save into a CSV for further reference\n",
    "temp_output_filepath = '../data/generated_intermediate_data/revised_politicians_by_country_with_pageinfo_and_quality_prediction_AUG.2024.csv'\n",
    "revised_politicians_with_pageinfo_and_scores_df.to_csv(temp_output_filepath, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Combining the datasets\n",
    "\n",
    "In this section, we first need to combine the dataset generated in the previous step (`revised_politicians_by_country_with_pageinfo_and_quality_prediction_AUG.2024.csv`) with the population data (`population_by_country_AUG.2024.csv`) using the common field - `country`. We also need to clean and standardize the country/region names before merging. \n",
    "\n",
    "#### 1.5.1 Load the population dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Geography</th>\n",
       "      <th>Population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WORLD</td>\n",
       "      <td>8009.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFRICA</td>\n",
       "      <td>1453.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NORTHERN AFRICA</td>\n",
       "      <td>256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>46.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Egypt</td>\n",
       "      <td>105.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Geography  Population\n",
       "0            WORLD      8009.0\n",
       "1           AFRICA      1453.0\n",
       "2  NORTHERN AFRICA       256.0\n",
       "3          Algeria        46.8\n",
       "4            Egypt       105.2"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population_df = pd.read_csv(\"../data/input_data/population_by_country_AUG.2024.csv\")\n",
    "population_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5.2 Identify Regions and Countries from the dataset\n",
    "\n",
    "When the 'Geography' is UPPER CASE, it means that it is a 'region'. On the other hand, if it is LOWER CASE, then it denotes a 'country'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>population</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>46.8</td>\n",
       "      <td>NORTHERN AFRICA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Egypt</td>\n",
       "      <td>105.2</td>\n",
       "      <td>NORTHERN AFRICA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Libya</td>\n",
       "      <td>6.9</td>\n",
       "      <td>NORTHERN AFRICA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Morocco</td>\n",
       "      <td>37.0</td>\n",
       "      <td>NORTHERN AFRICA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sudan</td>\n",
       "      <td>48.1</td>\n",
       "      <td>NORTHERN AFRICA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   country  population           region\n",
       "0  Algeria        46.8  NORTHERN AFRICA\n",
       "1    Egypt       105.2  NORTHERN AFRICA\n",
       "2    Libya         6.9  NORTHERN AFRICA\n",
       "3  Morocco        37.0  NORTHERN AFRICA\n",
       "4    Sudan        48.1  NORTHERN AFRICA"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population_df['region'] = population_df['Geography'].apply(lambda x: x if x.isupper() else np.nan).ffill()  # get the region name\n",
    "\n",
    "# Drop the rows where the Geography is all uppercase (Region)\n",
    "revised_population_df = population_df[~population_df['Geography'].str.isupper()].reset_index(drop=True)\n",
    "revised_population_df.rename(columns = {\"Geography\": \"country\", \"Population\": \"population\"}, inplace=True)\n",
    "revised_population_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5.3 Merge the population dataset with the politicians dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>region</th>\n",
       "      <th>population</th>\n",
       "      <th>article_title</th>\n",
       "      <th>revision_id</th>\n",
       "      <th>quality_prediction</th>\n",
       "      <th>join_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>SOUTH ASIA</td>\n",
       "      <td>42.4</td>\n",
       "      <td>Majah Ha Adrif</td>\n",
       "      <td>1.233203e+09</td>\n",
       "      <td>Start</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>SOUTH ASIA</td>\n",
       "      <td>42.4</td>\n",
       "      <td>Haroon al-Afghani</td>\n",
       "      <td>1.230460e+09</td>\n",
       "      <td>B</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>SOUTH ASIA</td>\n",
       "      <td>42.4</td>\n",
       "      <td>Tayyab Agha</td>\n",
       "      <td>1.225662e+09</td>\n",
       "      <td>Start</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>SOUTH ASIA</td>\n",
       "      <td>42.4</td>\n",
       "      <td>Khadija Zahra Ahmadi</td>\n",
       "      <td>1.234742e+09</td>\n",
       "      <td>Stub</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>SOUTH ASIA</td>\n",
       "      <td>42.4</td>\n",
       "      <td>Aziza Ahmadyar</td>\n",
       "      <td>1.195651e+09</td>\n",
       "      <td>Start</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       country      region  population         article_title   revision_id  \\\n",
       "0  Afghanistan  SOUTH ASIA        42.4        Majah Ha Adrif  1.233203e+09   \n",
       "1  Afghanistan  SOUTH ASIA        42.4     Haroon al-Afghani  1.230460e+09   \n",
       "2  Afghanistan  SOUTH ASIA        42.4           Tayyab Agha  1.225662e+09   \n",
       "3  Afghanistan  SOUTH ASIA        42.4  Khadija Zahra Ahmadi  1.234742e+09   \n",
       "4  Afghanistan  SOUTH ASIA        42.4        Aziza Ahmadyar  1.195651e+09   \n",
       "\n",
       "  quality_prediction join_type  \n",
       "0              Start      both  \n",
       "1                  B      both  \n",
       "2              Start      both  \n",
       "3               Stub      both  \n",
       "4              Start      both  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "politicians_population_df = pd.merge(revised_politicians_with_pageinfo_and_scores_df, \n",
    "                                     revised_population_df, on=[\"country\"], \n",
    "                                     how=\"outer\", indicator=True)\n",
    "politicians_population_df = politicians_population_df[[\"country\", \"region\", \"population\", \"name\", \"revision_id\", \"quality_prediction\", \"_merge\"]]\n",
    "politicians_population_df.rename(columns = {\"name\": \"article_title\", \"quality_predictionn\": \"article_quality\", \"_merge\": \"join_type\"}, inplace=True)\n",
    "politicians_population_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5.4 Obtain the list of countries with no match\n",
    "\n",
    "The homework specifies \"countries with no match\" as the list of countries with either the population dataset not having an entry for the equivalent Wikipedia country, or the wWkipedia article not having an associated population data associated to it.\n",
    "- We will save the list of countries with no match in the path: `data/generated_output_data/wp_countries-no_match.txt`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Countries with no population data associated with them: ['Guinea-Bissau', 'Korea, South', 'Korean']\n",
      "\n",
      "Countries with no politicians associated with them: ['Andorra', 'Australia', 'Brunei', 'Canada', 'China (Hong Kong SAR)', 'China (Macao SAR)', 'Curacao', 'Denmark', 'Dominica', 'Fiji', 'French Guiana', 'French Polynesia', 'Georgia', 'Guadeloupe', 'Guam', 'GuineaBissau', 'Iceland', 'Ireland', 'Jamaica', 'Kiribati', 'Korea (North)', 'Korea (South)', 'Liechtenstein', 'Martinique', 'Mauritius', 'Mayotte', 'Mexico', 'Nauru', 'Netherlands', 'New Caledonia', 'New Zealand', 'Palau', 'Philippines', 'Puerto Rico', 'Reunion', 'Romania', 'San Marino', 'Sao Tome and Principe', 'Suriname', 'United Kingdom', 'United States', 'Western Sahara', 'eSwatini']\n"
     ]
    }
   ],
   "source": [
    "# Countries with no population data adssociated with them\n",
    "countries_missing_population = politicians_population_df[politicians_population_df[\"join_type\"] == \"left_only\"]\n",
    "countries_missing_population_list = countries_missing_population[\"country\"].unique().tolist()\n",
    "print(\"Countries with no population data associated with them:\", countries_missing_population_list)\n",
    "\n",
    "# Countries with no politicians associated with them (population data with no countries associated with them)\n",
    "countries_missing_politicians = politicians_population_df[politicians_population_df[\"join_type\"] == \"right_only\"]\n",
    "countries_missing_politicians_list = countries_missing_politicians[\"country\"].unique().tolist()\n",
    "print(\"\\nCountries with no politicians associated with them:\", countries_missing_politicians_list)\n",
    "\n",
    "# To obtain the countries with no match, we need to combine both the lists above,\n",
    "countries_no_match = countries_missing_population_list + countries_missing_politicians_list\n",
    "# write to a file called wp_countries-no_match.tx\n",
    "with open('../data/generated_output_data/wp_countries-no_match.txt', 'w+') as file:\n",
    "    for country in countries_no_match:\n",
    "        file.write(country + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5.5 Obtain data with successful matches\n",
    "\n",
    "For countries with successful matches, the merged dataset will have Wikipedia politicians article data (with ORES prediction) and population data. \n",
    "- We will save this data in the path: `data/generated_output_data/wp_politicians_by_country.csv` and it can be used for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>region</th>\n",
       "      <th>population</th>\n",
       "      <th>article_title</th>\n",
       "      <th>revision_id</th>\n",
       "      <th>quality_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>SOUTH ASIA</td>\n",
       "      <td>42.4</td>\n",
       "      <td>Majah Ha Adrif</td>\n",
       "      <td>1.233203e+09</td>\n",
       "      <td>Start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>SOUTH ASIA</td>\n",
       "      <td>42.4</td>\n",
       "      <td>Haroon al-Afghani</td>\n",
       "      <td>1.230460e+09</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>SOUTH ASIA</td>\n",
       "      <td>42.4</td>\n",
       "      <td>Tayyab Agha</td>\n",
       "      <td>1.225662e+09</td>\n",
       "      <td>Start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>SOUTH ASIA</td>\n",
       "      <td>42.4</td>\n",
       "      <td>Khadija Zahra Ahmadi</td>\n",
       "      <td>1.234742e+09</td>\n",
       "      <td>Stub</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>SOUTH ASIA</td>\n",
       "      <td>42.4</td>\n",
       "      <td>Aziza Ahmadyar</td>\n",
       "      <td>1.195651e+09</td>\n",
       "      <td>Start</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       country      region  population         article_title   revision_id  \\\n",
       "0  Afghanistan  SOUTH ASIA        42.4        Majah Ha Adrif  1.233203e+09   \n",
       "1  Afghanistan  SOUTH ASIA        42.4     Haroon al-Afghani  1.230460e+09   \n",
       "2  Afghanistan  SOUTH ASIA        42.4           Tayyab Agha  1.225662e+09   \n",
       "3  Afghanistan  SOUTH ASIA        42.4  Khadija Zahra Ahmadi  1.234742e+09   \n",
       "4  Afghanistan  SOUTH ASIA        42.4        Aziza Ahmadyar  1.195651e+09   \n",
       "\n",
       "  quality_prediction  \n",
       "0              Start  \n",
       "1                  B  \n",
       "2              Start  \n",
       "3               Stub  \n",
       "4              Start  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries_with_match_df = politicians_population_df[politicians_population_df[\"join_type\"] == \"both\"].copy()\n",
    "countries_with_match_df.drop(columns=[\"join_type\"], inplace=True)\n",
    "countries_with_match_df.to_csv(\"../data/generated_output_data/wp_politicians_by_country.csv\", index=False)# save the dataframe for further analysis\n",
    "countries_with_match_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Analysis\n",
    "\n",
    "In this section, we will calculate two important metrics: `total-articles-per-capita` and `high-quality-articles-per-capita`. These metrics tells us the availability and quality of Wikipedia articles relative to the population of each country and region.\n",
    "\n",
    "First let us make sure that we only have rows wih articles where population is > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_with_match_df = countries_with_match_df[countries_with_match_df['population'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us then identify the \"high quality\" articles (articles that have article_quality \"FA\" (featured article) or \"GA\" (good article))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define high-quality articles\n",
    "countries_with_match_df['is_high_quality'] = countries_with_match_df['quality_prediction'].isin(['FA', 'GA'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to get the total articles (specifically list the count of high quality articles) by country and region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>region</th>\n",
       "      <th>total_articles</th>\n",
       "      <th>high_quality_articles</th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>SOUTH ASIA</td>\n",
       "      <td>85</td>\n",
       "      <td>3</td>\n",
       "      <td>42400000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>SOUTHERN EUROPE</td>\n",
       "      <td>69</td>\n",
       "      <td>7</td>\n",
       "      <td>2700000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>NORTHERN AFRICA</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>46800000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Angola</td>\n",
       "      <td>MIDDLE AFRICA</td>\n",
       "      <td>58</td>\n",
       "      <td>2</td>\n",
       "      <td>36700000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Antigua and Barbuda</td>\n",
       "      <td>CARIBBEAN</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>100000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               country           region  total_articles  \\\n",
       "0          Afghanistan       SOUTH ASIA              85   \n",
       "1              Albania  SOUTHERN EUROPE              69   \n",
       "2              Algeria  NORTHERN AFRICA              71   \n",
       "3               Angola    MIDDLE AFRICA              58   \n",
       "4  Antigua and Barbuda        CARIBBEAN              33   \n",
       "\n",
       "   high_quality_articles  population  \n",
       "0                      3  42400000.0  \n",
       "1                      7   2700000.0  \n",
       "2                      1  46800000.0  \n",
       "3                      2  36700000.0  \n",
       "4                      0    100000.0  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get total articles and high-quality articles by country and region\n",
    "aggregated_politicians_population_df = (countries_with_match_df.groupby(['country', 'region']).agg(total_articles=('article_title', 'count'),\n",
    "                                                                            high_quality_articles=('is_high_quality', 'sum'),\n",
    "                                                                            population=('population', 'first')).reset_index())\n",
    "aggregated_politicians_population_df['population'] *= 1_000_000  # Let us also make sure that we represent the population count as it is and not in millions\n",
    "aggregated_politicians_population_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let us calculate the articles per capita,\n",
    "\n",
    "- `total_articles_per_capita`: Represents the number of articles available for each person in a given country or region.\n",
    "- `high_quality_articles_per_capita'`: Represents the number of high-quality articles available per person."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>region</th>\n",
       "      <th>total_articles</th>\n",
       "      <th>high_quality_articles</th>\n",
       "      <th>population</th>\n",
       "      <th>total_articles_per_capita</th>\n",
       "      <th>high_quality_articles_per_capita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>SOUTH ASIA</td>\n",
       "      <td>85</td>\n",
       "      <td>3</td>\n",
       "      <td>42400000.0</td>\n",
       "      <td>0.000002005</td>\n",
       "      <td>0.000000071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>SOUTHERN EUROPE</td>\n",
       "      <td>69</td>\n",
       "      <td>7</td>\n",
       "      <td>2700000.0</td>\n",
       "      <td>0.000025556</td>\n",
       "      <td>0.000002593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>NORTHERN AFRICA</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>46800000.0</td>\n",
       "      <td>0.000001517</td>\n",
       "      <td>0.000000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Angola</td>\n",
       "      <td>MIDDLE AFRICA</td>\n",
       "      <td>58</td>\n",
       "      <td>2</td>\n",
       "      <td>36700000.0</td>\n",
       "      <td>0.000001580</td>\n",
       "      <td>0.000000054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Antigua and Barbuda</td>\n",
       "      <td>CARIBBEAN</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>0.000330000</td>\n",
       "      <td>0.000000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               country           region  total_articles  \\\n",
       "0          Afghanistan       SOUTH ASIA              85   \n",
       "1              Albania  SOUTHERN EUROPE              69   \n",
       "2              Algeria  NORTHERN AFRICA              71   \n",
       "3               Angola    MIDDLE AFRICA              58   \n",
       "4  Antigua and Barbuda        CARIBBEAN              33   \n",
       "\n",
       "   high_quality_articles  population total_articles_per_capita  \\\n",
       "0                      3  42400000.0               0.000002005   \n",
       "1                      7   2700000.0               0.000025556   \n",
       "2                      1  46800000.0               0.000001517   \n",
       "3                      2  36700000.0               0.000001580   \n",
       "4                      0    100000.0               0.000330000   \n",
       "\n",
       "  high_quality_articles_per_capita  \n",
       "0                      0.000000071  \n",
       "1                      0.000002593  \n",
       "2                      0.000000021  \n",
       "3                      0.000000054  \n",
       "4                      0.000000000  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregated_politicians_population_df['total_articles_per_capita'] = aggregated_politicians_population_df['total_articles'] / aggregated_politicians_population_df['population']\n",
    "aggregated_politicians_population_df['high_quality_articles_per_capita'] = aggregated_politicians_population_df['high_quality_articles'] / aggregated_politicians_population_df['population']\n",
    "\n",
    "# For better readability, let's have upto 9 decimal points\n",
    "aggregated_politicians_population_df['total_articles_per_capita'] = aggregated_politicians_population_df['total_articles_per_capita'].apply(lambda x: f\"{x:.9f}\")\n",
    "aggregated_politicians_population_df['high_quality_articles_per_capita'] = aggregated_politicians_population_df['high_quality_articles_per_capita'].apply(lambda x: f\"{x:.9f}\")\n",
    "\n",
    "aggregated_politicians_population_df.to_csv('../data/generated_intermediate_data/articles_per_capita_analysis.csv', index=False) # Save for further analysis/quick reference\n",
    "aggregated_politicians_population_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data Analysis/Results\n",
    "\n",
    "In this sub-section, we summarize the results of the analysis by creating 6 tables,\n",
    "- **Top 10 countries by coverage**\n",
    "- **Bottom 10 countries by coverage** \n",
    "- **Top 10 countries by high quality**\n",
    "- **Bottom 10 countries by high quality** \n",
    "- **Geographic regions by total coverage** \n",
    "- **Geographic regions by high quality coverage** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Top 10 countries by coverage\n",
    "\n",
    "In this section, we calculate the number of Articles per person for each country and rank them in descending order. The top 10 countries with the highest total articles per capita will be displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>region</th>\n",
       "      <th>total_articles</th>\n",
       "      <th>high_quality_articles</th>\n",
       "      <th>population</th>\n",
       "      <th>total_articles_per_capita</th>\n",
       "      <th>high_quality_articles_per_capita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Antigua and Barbuda</td>\n",
       "      <td>CARIBBEAN</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>0.000330000</td>\n",
       "      <td>0.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Federated States of Micronesia</td>\n",
       "      <td>OCEANIA</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>0.000140000</td>\n",
       "      <td>0.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Marshall Islands</td>\n",
       "      <td>OCEANIA</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>0.000130000</td>\n",
       "      <td>0.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>Tonga</td>\n",
       "      <td>OCEANIA</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>0.000100000</td>\n",
       "      <td>0.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Barbados</td>\n",
       "      <td>CARIBBEAN</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>300000.0</td>\n",
       "      <td>0.000083333</td>\n",
       "      <td>0.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>Seychelles</td>\n",
       "      <td>EASTERN AFRICA</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>0.000060000</td>\n",
       "      <td>0.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Montenegro</td>\n",
       "      <td>SOUTHERN EUROPE</td>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>0.000060000</td>\n",
       "      <td>0.000005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Bhutan</td>\n",
       "      <td>SOUTH ASIA</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>800000.0</td>\n",
       "      <td>0.000055000</td>\n",
       "      <td>0.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Maldives</td>\n",
       "      <td>SOUTH ASIA</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>0.000055000</td>\n",
       "      <td>0.000001667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>Samoa</td>\n",
       "      <td>OCEANIA</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>0.000040000</td>\n",
       "      <td>0.000000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            country           region  total_articles  \\\n",
       "4               Antigua and Barbuda        CARIBBEAN              33   \n",
       "51   Federated States of Micronesia          OCEANIA              14   \n",
       "93                 Marshall Islands          OCEANIA              13   \n",
       "148                           Tonga          OCEANIA              10   \n",
       "12                         Barbados        CARIBBEAN              25   \n",
       "124                      Seychelles   EASTERN AFRICA               6   \n",
       "97                       Montenegro  SOUTHERN EUROPE              36   \n",
       "17                           Bhutan       SOUTH ASIA              44   \n",
       "90                         Maldives       SOUTH ASIA              33   \n",
       "120                           Samoa          OCEANIA               8   \n",
       "\n",
       "     high_quality_articles  population total_articles_per_capita  \\\n",
       "4                        0    100000.0               0.000330000   \n",
       "51                       0    100000.0               0.000140000   \n",
       "93                       0    100000.0               0.000130000   \n",
       "148                      0    100000.0               0.000100000   \n",
       "12                       0    300000.0               0.000083333   \n",
       "124                      0    100000.0               0.000060000   \n",
       "97                       3    600000.0               0.000060000   \n",
       "17                       0    800000.0               0.000055000   \n",
       "90                       1    600000.0               0.000055000   \n",
       "120                      0    200000.0               0.000040000   \n",
       "\n",
       "    high_quality_articles_per_capita  \n",
       "4                        0.000000000  \n",
       "51                       0.000000000  \n",
       "93                       0.000000000  \n",
       "148                      0.000000000  \n",
       "12                       0.000000000  \n",
       "124                      0.000000000  \n",
       "97                       0.000005000  \n",
       "17                       0.000000000  \n",
       "90                       0.000001667  \n",
       "120                      0.000000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "top_10_by_coverage = aggregated_politicians_population_df.sort_values(by='total_articles_per_capita', ascending=False).head(10)\n",
    "display(top_10_by_coverage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "\n",
    "A noticeable trend above is that small countries like Antigua and Barbuda and Federated States of Micronesia dominate the list. The population in these countries are very less, so even with less number of articles, their articles per person are quite high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Bottom 10 countries by coverage\n",
    "We rank the countries in ascending order and display the 10 countries with the lowest number of total articles per capita."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>region</th>\n",
       "      <th>total_articles</th>\n",
       "      <th>high_quality_articles</th>\n",
       "      <th>population</th>\n",
       "      <th>total_articles_per_capita</th>\n",
       "      <th>high_quality_articles_per_capita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>China</td>\n",
       "      <td>EAST ASIA</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1.411300e+09</td>\n",
       "      <td>0.000000011</td>\n",
       "      <td>0.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Ghana</td>\n",
       "      <td>WESTERN AFRICA</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3.410000e+07</td>\n",
       "      <td>0.000000088</td>\n",
       "      <td>0.000000029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>India</td>\n",
       "      <td>SOUTH ASIA</td>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "      <td>1.428600e+09</td>\n",
       "      <td>0.000000106</td>\n",
       "      <td>0.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Saudi Arabia</td>\n",
       "      <td>WESTERN ASIA</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3.690000e+07</td>\n",
       "      <td>0.000000136</td>\n",
       "      <td>0.000000054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>EASTERN AFRICA</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2.020000e+07</td>\n",
       "      <td>0.000000149</td>\n",
       "      <td>0.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Norway</td>\n",
       "      <td>NORTHERN EUROPE</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.500000e+06</td>\n",
       "      <td>0.000000182</td>\n",
       "      <td>0.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Israel</td>\n",
       "      <td>WESTERN ASIA</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9.800000e+06</td>\n",
       "      <td>0.000000204</td>\n",
       "      <td>0.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Egypt</td>\n",
       "      <td>NORTHERN AFRICA</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>1.052000e+08</td>\n",
       "      <td>0.000000304</td>\n",
       "      <td>0.000000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Cote d'Ivoire</td>\n",
       "      <td>WESTERN AFRICA</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>3.090000e+07</td>\n",
       "      <td>0.000000324</td>\n",
       "      <td>0.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Ethiopia</td>\n",
       "      <td>EASTERN AFRICA</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>1.265000e+08</td>\n",
       "      <td>0.000000340</td>\n",
       "      <td>0.000000016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           country           region  total_articles  high_quality_articles  \\\n",
       "31           China        EAST ASIA              16                      0   \n",
       "57           Ghana   WESTERN AFRICA               3                      1   \n",
       "66           India       SOUTH ASIA             151                      0   \n",
       "121   Saudi Arabia     WESTERN ASIA               5                      2   \n",
       "162         Zambia   EASTERN AFRICA               3                      0   \n",
       "107         Norway  NORTHERN EUROPE               1                      0   \n",
       "70          Israel     WESTERN ASIA               2                      0   \n",
       "45           Egypt  NORTHERN AFRICA              32                      1   \n",
       "37   Cote d'Ivoire   WESTERN AFRICA              10                      0   \n",
       "50        Ethiopia   EASTERN AFRICA              43                      2   \n",
       "\n",
       "       population total_articles_per_capita high_quality_articles_per_capita  \n",
       "31   1.411300e+09               0.000000011                      0.000000000  \n",
       "57   3.410000e+07               0.000000088                      0.000000029  \n",
       "66   1.428600e+09               0.000000106                      0.000000000  \n",
       "121  3.690000e+07               0.000000136                      0.000000054  \n",
       "162  2.020000e+07               0.000000149                      0.000000000  \n",
       "107  5.500000e+06               0.000000182                      0.000000000  \n",
       "70   9.800000e+06               0.000000204                      0.000000000  \n",
       "45   1.052000e+08               0.000000304                      0.000000010  \n",
       "37   3.090000e+07               0.000000324                      0.000000000  \n",
       "50   1.265000e+08               0.000000340                      0.000000016  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bottom_10_by_coverage = aggregated_politicians_population_df.sort_values(by='total_articles_per_capita', ascending=True).head(10)\n",
    "display(bottom_10_by_coverage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "\n",
    "Over here, we see a mix of large population countries like China and India. These countries have very low total articles per capita because their large populations hides whatever article count they have, even if it is a decent number of articles to have."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Top 10 countries by high quality\n",
    "Here we have the countries with the highest number of high-quality articles (FA or GA class) per capita, ranked in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>region</th>\n",
       "      <th>total_articles</th>\n",
       "      <th>high_quality_articles</th>\n",
       "      <th>population</th>\n",
       "      <th>total_articles_per_capita</th>\n",
       "      <th>high_quality_articles_per_capita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Montenegro</td>\n",
       "      <td>SOUTHERN EUROPE</td>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>0.000060000</td>\n",
       "      <td>0.000005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Luxembourg</td>\n",
       "      <td>WESTERN EUROPE</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>700000.0</td>\n",
       "      <td>0.000038571</td>\n",
       "      <td>0.000002857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>SOUTHERN EUROPE</td>\n",
       "      <td>69</td>\n",
       "      <td>7</td>\n",
       "      <td>2700000.0</td>\n",
       "      <td>0.000025556</td>\n",
       "      <td>0.000002593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Kosovo</td>\n",
       "      <td>SOUTHERN EUROPE</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>1700000.0</td>\n",
       "      <td>0.000015294</td>\n",
       "      <td>0.000002353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Maldives</td>\n",
       "      <td>SOUTH ASIA</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>600000.0</td>\n",
       "      <td>0.000055000</td>\n",
       "      <td>0.000001667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Croatia</td>\n",
       "      <td>SOUTHERN EUROPE</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>3800000.0</td>\n",
       "      <td>0.000016842</td>\n",
       "      <td>0.000001316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Guyana</td>\n",
       "      <td>SOUTH AMERICA</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>800000.0</td>\n",
       "      <td>0.000021250</td>\n",
       "      <td>0.000001250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Palestinian Territory</td>\n",
       "      <td>WESTERN ASIA</td>\n",
       "      <td>61</td>\n",
       "      <td>6</td>\n",
       "      <td>5500000.0</td>\n",
       "      <td>0.000011091</td>\n",
       "      <td>0.000001091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Lithuania</td>\n",
       "      <td>NORTHERN EUROPE</td>\n",
       "      <td>57</td>\n",
       "      <td>3</td>\n",
       "      <td>2900000.0</td>\n",
       "      <td>0.000019655</td>\n",
       "      <td>0.000001034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>Slovenia</td>\n",
       "      <td>SOUTHERN EUROPE</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>2100000.0</td>\n",
       "      <td>0.000018095</td>\n",
       "      <td>0.000000952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   country           region  total_articles  \\\n",
       "97              Montenegro  SOUTHERN EUROPE              36   \n",
       "86              Luxembourg   WESTERN EUROPE              27   \n",
       "1                  Albania  SOUTHERN EUROPE              69   \n",
       "76                  Kosovo  SOUTHERN EUROPE              26   \n",
       "90                Maldives       SOUTH ASIA              33   \n",
       "38                 Croatia  SOUTHERN EUROPE              64   \n",
       "62                  Guyana    SOUTH AMERICA              17   \n",
       "110  Palestinian Territory     WESTERN ASIA              61   \n",
       "85               Lithuania  NORTHERN EUROPE              57   \n",
       "128               Slovenia  SOUTHERN EUROPE              38   \n",
       "\n",
       "     high_quality_articles  population total_articles_per_capita  \\\n",
       "97                       3    600000.0               0.000060000   \n",
       "86                       2    700000.0               0.000038571   \n",
       "1                        7   2700000.0               0.000025556   \n",
       "76                       4   1700000.0               0.000015294   \n",
       "90                       1    600000.0               0.000055000   \n",
       "38                       5   3800000.0               0.000016842   \n",
       "62                       1    800000.0               0.000021250   \n",
       "110                      6   5500000.0               0.000011091   \n",
       "85                       3   2900000.0               0.000019655   \n",
       "128                      2   2100000.0               0.000018095   \n",
       "\n",
       "    high_quality_articles_per_capita  \n",
       "97                       0.000005000  \n",
       "86                       0.000002857  \n",
       "1                        0.000002593  \n",
       "76                       0.000002353  \n",
       "90                       0.000001667  \n",
       "38                       0.000001316  \n",
       "62                       0.000001250  \n",
       "110                      0.000001091  \n",
       "85                       0.000001034  \n",
       "128                      0.000000952  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "top_10_by_high_quality = aggregated_politicians_population_df.sort_values(by='high_quality_articles_per_capita', ascending=False).head(10)\n",
    "display(top_10_by_high_quality)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "\n",
    "Similar to what we observed in 2.1, here too we have many countries with small populations ranked high, eventhough they have less number of high-quality articles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Bottom 10 countries by high quality\n",
    "Here we will show the countries with the fewest high-quality articles per capita, ranked in ascending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>region</th>\n",
       "      <th>total_articles</th>\n",
       "      <th>high_quality_articles</th>\n",
       "      <th>population</th>\n",
       "      <th>total_articles_per_capita</th>\n",
       "      <th>high_quality_articles_per_capita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>EASTERN AFRICA</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>16700000.0</td>\n",
       "      <td>0.000004132</td>\n",
       "      <td>0.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Qatar</td>\n",
       "      <td>WESTERN ASIA</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2700000.0</td>\n",
       "      <td>0.000001852</td>\n",
       "      <td>0.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Grenada</td>\n",
       "      <td>CARIBBEAN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>0.000020000</td>\n",
       "      <td>0.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>Samoa</td>\n",
       "      <td>OCEANIA</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>0.000040000</td>\n",
       "      <td>0.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Gambia</td>\n",
       "      <td>WESTERN AFRICA</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>2800000.0</td>\n",
       "      <td>0.000006429</td>\n",
       "      <td>0.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Senegal</td>\n",
       "      <td>WESTERN AFRICA</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>18300000.0</td>\n",
       "      <td>0.000001694</td>\n",
       "      <td>0.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>Seychelles</td>\n",
       "      <td>EASTERN AFRICA</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>0.000060000</td>\n",
       "      <td>0.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Federated States of Micronesia</td>\n",
       "      <td>OCEANIA</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>0.000140000</td>\n",
       "      <td>0.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Estonia</td>\n",
       "      <td>NORTHERN EUROPE</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1400000.0</td>\n",
       "      <td>0.000010714</td>\n",
       "      <td>0.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Eritrea</td>\n",
       "      <td>EASTERN AFRICA</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>3700000.0</td>\n",
       "      <td>0.000004054</td>\n",
       "      <td>0.000000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            country           region  total_articles  \\\n",
       "163                        Zimbabwe   EASTERN AFRICA              69   \n",
       "117                           Qatar     WESTERN ASIA               5   \n",
       "59                          Grenada        CARIBBEAN               2   \n",
       "120                           Samoa          OCEANIA               8   \n",
       "55                           Gambia   WESTERN AFRICA              18   \n",
       "122                         Senegal   WESTERN AFRICA              31   \n",
       "124                      Seychelles   EASTERN AFRICA               6   \n",
       "51   Federated States of Micronesia          OCEANIA              14   \n",
       "49                          Estonia  NORTHERN EUROPE              15   \n",
       "48                          Eritrea   EASTERN AFRICA              15   \n",
       "\n",
       "     high_quality_articles  population total_articles_per_capita  \\\n",
       "163                      0  16700000.0               0.000004132   \n",
       "117                      0   2700000.0               0.000001852   \n",
       "59                       0    100000.0               0.000020000   \n",
       "120                      0    200000.0               0.000040000   \n",
       "55                       0   2800000.0               0.000006429   \n",
       "122                      0  18300000.0               0.000001694   \n",
       "124                      0    100000.0               0.000060000   \n",
       "51                       0    100000.0               0.000140000   \n",
       "49                       0   1400000.0               0.000010714   \n",
       "48                       0   3700000.0               0.000004054   \n",
       "\n",
       "    high_quality_articles_per_capita  \n",
       "163                      0.000000000  \n",
       "117                      0.000000000  \n",
       "59                       0.000000000  \n",
       "120                      0.000000000  \n",
       "55                       0.000000000  \n",
       "122                      0.000000000  \n",
       "124                      0.000000000  \n",
       "51                       0.000000000  \n",
       "49                       0.000000000  \n",
       "48                       0.000000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bottom_10_by_high_quality = aggregated_politicians_population_df.sort_values(by='high_quality_articles_per_capita', ascending=True).head(10)\n",
    "display(bottom_10_by_high_quality)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "\n",
    "Similar to what we observed in section 2.2, compared to the population, though we expect these countries to have high number of high-quality articles, they fail to have so. The bottom 10 countries have 0 high-quality articles and are just ranked randomly by the system!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Geographic regions by total coverage\n",
    "Instead of individual countries, this table aggregates the data by geographic regions. It ranks regions based on the total number of articles per capita, in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>total_articles</th>\n",
       "      <th>population</th>\n",
       "      <th>total_articles_per_capita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NORTHERN EUROPE</td>\n",
       "      <td>188</td>\n",
       "      <td>2.780000e+07</td>\n",
       "      <td>6.762590e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>OCEANIA</td>\n",
       "      <td>71</td>\n",
       "      <td>1.110000e+07</td>\n",
       "      <td>6.396396e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CARIBBEAN</td>\n",
       "      <td>219</td>\n",
       "      <td>3.660000e+07</td>\n",
       "      <td>5.983607e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SOUTHERN EUROPE</td>\n",
       "      <td>785</td>\n",
       "      <td>1.515000e+08</td>\n",
       "      <td>5.181518e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CENTRAL AMERICA</td>\n",
       "      <td>186</td>\n",
       "      <td>5.130000e+07</td>\n",
       "      <td>3.625731e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>WESTERN EUROPE</td>\n",
       "      <td>486</td>\n",
       "      <td>1.813000e+08</td>\n",
       "      <td>2.680640e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EASTERN EUROPE</td>\n",
       "      <td>701</td>\n",
       "      <td>2.662000e+08</td>\n",
       "      <td>2.633358e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>WESTERN ASIA</td>\n",
       "      <td>607</td>\n",
       "      <td>2.954000e+08</td>\n",
       "      <td>2.054841e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SOUTHERN AFRICA</td>\n",
       "      <td>123</td>\n",
       "      <td>6.830000e+07</td>\n",
       "      <td>1.800878e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EASTERN AFRICA</td>\n",
       "      <td>663</td>\n",
       "      <td>4.809000e+08</td>\n",
       "      <td>1.378665e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SOUTH AMERICA</td>\n",
       "      <td>569</td>\n",
       "      <td>4.250000e+08</td>\n",
       "      <td>1.338824e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CENTRAL ASIA</td>\n",
       "      <td>103</td>\n",
       "      <td>8.040000e+07</td>\n",
       "      <td>1.281095e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>WESTERN AFRICA</td>\n",
       "      <td>514</td>\n",
       "      <td>4.401000e+08</td>\n",
       "      <td>1.167916e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NORTHERN AFRICA</td>\n",
       "      <td>298</td>\n",
       "      <td>2.559000e+08</td>\n",
       "      <td>1.164517e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MIDDLE AFRICA</td>\n",
       "      <td>231</td>\n",
       "      <td>2.018000e+08</td>\n",
       "      <td>1.144698e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SOUTHEAST ASIA</td>\n",
       "      <td>394</td>\n",
       "      <td>5.641000e+08</td>\n",
       "      <td>6.984577e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SOUTH ASIA</td>\n",
       "      <td>667</td>\n",
       "      <td>2.029200e+09</td>\n",
       "      <td>3.287010e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EAST ASIA</td>\n",
       "      <td>151</td>\n",
       "      <td>1.562700e+09</td>\n",
       "      <td>9.662763e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             region  total_articles    population  total_articles_per_capita\n",
       "8   NORTHERN EUROPE             188  2.780000e+07               6.762590e-06\n",
       "9           OCEANIA              71  1.110000e+07               6.396396e-06\n",
       "0         CARIBBEAN             219  3.660000e+07               5.983607e-06\n",
       "14  SOUTHERN EUROPE             785  1.515000e+08               5.181518e-06\n",
       "1   CENTRAL AMERICA             186  5.130000e+07               3.625731e-06\n",
       "17   WESTERN EUROPE             486  1.813000e+08               2.680640e-06\n",
       "5    EASTERN EUROPE             701  2.662000e+08               2.633358e-06\n",
       "16     WESTERN ASIA             607  2.954000e+08               2.054841e-06\n",
       "13  SOUTHERN AFRICA             123  6.830000e+07               1.800878e-06\n",
       "4    EASTERN AFRICA             663  4.809000e+08               1.378665e-06\n",
       "10    SOUTH AMERICA             569  4.250000e+08               1.338824e-06\n",
       "2      CENTRAL ASIA             103  8.040000e+07               1.281095e-06\n",
       "15   WESTERN AFRICA             514  4.401000e+08               1.167916e-06\n",
       "7   NORTHERN AFRICA             298  2.559000e+08               1.164517e-06\n",
       "6     MIDDLE AFRICA             231  2.018000e+08               1.144698e-06\n",
       "12   SOUTHEAST ASIA             394  5.641000e+08               6.984577e-07\n",
       "11       SOUTH ASIA             667  2.029200e+09               3.287010e-07\n",
       "3         EAST ASIA             151  1.562700e+09               9.662763e-08"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute the total coverage for a geographical region\n",
    "regions_total_coverage = aggregated_politicians_population_df.groupby('region').agg({'total_articles': 'sum',\n",
    "                                                                                     'population': 'sum'}).reset_index()\n",
    "\n",
    "# Calculate the total articles per capita for each region\n",
    "regions_total_coverage['total_articles_per_capita'] = regions_total_coverage['total_articles'] / regions_total_coverage['population']\n",
    "\n",
    "# Sort by total articles per capita in descending order\n",
    "regions_total_coverage_sorted = regions_total_coverage.sort_values(by='total_articles_per_capita', ascending=False)\n",
    "display(regions_total_coverage_sorted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "\n",
    "- Northern Europe has the highest number of articles per person, i.e., relative to it's population, there are a lot of political content available here.\n",
    "- Oceania and the Caribbean are just behind. On the other hand\n",
    "- East Asia has the lowest articles per person. Compared to it's large population, there’s not much political discussion happening here.\n",
    "- Though South Asia has a total of 667 articles, because it's population is over 2 billion, the number of articles per person is quite low. \n",
    "- Similarly, Eastern Africa and Western Africa have many articles, but their large populations result them to have low per person coverage. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Geographic regions by high quality coverage\n",
    "Similar to the previous table, but focused on high-quality articles per capita in each region, ranked in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>high_quality_articles</th>\n",
       "      <th>population</th>\n",
       "      <th>high_quality_articles_per_capita</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SOUTHERN EUROPE</td>\n",
       "      <td>53</td>\n",
       "      <td>1.515000e+08</td>\n",
       "      <td>3.498350e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NORTHERN EUROPE</td>\n",
       "      <td>8</td>\n",
       "      <td>2.780000e+07</td>\n",
       "      <td>2.877698e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CARIBBEAN</td>\n",
       "      <td>9</td>\n",
       "      <td>3.660000e+07</td>\n",
       "      <td>2.459016e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CENTRAL AMERICA</td>\n",
       "      <td>10</td>\n",
       "      <td>5.130000e+07</td>\n",
       "      <td>1.949318e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EASTERN EUROPE</td>\n",
       "      <td>37</td>\n",
       "      <td>2.662000e+08</td>\n",
       "      <td>1.389932e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SOUTHERN AFRICA</td>\n",
       "      <td>8</td>\n",
       "      <td>6.830000e+07</td>\n",
       "      <td>1.171303e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>WESTERN EUROPE</td>\n",
       "      <td>21</td>\n",
       "      <td>1.813000e+08</td>\n",
       "      <td>1.158301e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>WESTERN ASIA</td>\n",
       "      <td>27</td>\n",
       "      <td>2.954000e+08</td>\n",
       "      <td>9.140149e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>OCEANIA</td>\n",
       "      <td>1</td>\n",
       "      <td>1.110000e+07</td>\n",
       "      <td>9.009009e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CENTRAL ASIA</td>\n",
       "      <td>5</td>\n",
       "      <td>8.040000e+07</td>\n",
       "      <td>6.218905e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NORTHERN AFRICA</td>\n",
       "      <td>15</td>\n",
       "      <td>2.559000e+08</td>\n",
       "      <td>5.861665e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SOUTH AMERICA</td>\n",
       "      <td>19</td>\n",
       "      <td>4.250000e+08</td>\n",
       "      <td>4.470588e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SOUTHEAST ASIA</td>\n",
       "      <td>25</td>\n",
       "      <td>5.641000e+08</td>\n",
       "      <td>4.431838e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MIDDLE AFRICA</td>\n",
       "      <td>8</td>\n",
       "      <td>2.018000e+08</td>\n",
       "      <td>3.964321e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EASTERN AFRICA</td>\n",
       "      <td>17</td>\n",
       "      <td>4.809000e+08</td>\n",
       "      <td>3.535038e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>WESTERN AFRICA</td>\n",
       "      <td>13</td>\n",
       "      <td>4.401000e+08</td>\n",
       "      <td>2.953874e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SOUTH ASIA</td>\n",
       "      <td>21</td>\n",
       "      <td>2.029200e+09</td>\n",
       "      <td>1.034891e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EAST ASIA</td>\n",
       "      <td>3</td>\n",
       "      <td>1.562700e+09</td>\n",
       "      <td>1.919754e-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             region  high_quality_articles    population  \\\n",
       "14  SOUTHERN EUROPE                     53  1.515000e+08   \n",
       "8   NORTHERN EUROPE                      8  2.780000e+07   \n",
       "0         CARIBBEAN                      9  3.660000e+07   \n",
       "1   CENTRAL AMERICA                     10  5.130000e+07   \n",
       "5    EASTERN EUROPE                     37  2.662000e+08   \n",
       "13  SOUTHERN AFRICA                      8  6.830000e+07   \n",
       "17   WESTERN EUROPE                     21  1.813000e+08   \n",
       "16     WESTERN ASIA                     27  2.954000e+08   \n",
       "9           OCEANIA                      1  1.110000e+07   \n",
       "2      CENTRAL ASIA                      5  8.040000e+07   \n",
       "7   NORTHERN AFRICA                     15  2.559000e+08   \n",
       "10    SOUTH AMERICA                     19  4.250000e+08   \n",
       "12   SOUTHEAST ASIA                     25  5.641000e+08   \n",
       "6     MIDDLE AFRICA                      8  2.018000e+08   \n",
       "4    EASTERN AFRICA                     17  4.809000e+08   \n",
       "15   WESTERN AFRICA                     13  4.401000e+08   \n",
       "11       SOUTH ASIA                     21  2.029200e+09   \n",
       "3         EAST ASIA                      3  1.562700e+09   \n",
       "\n",
       "    high_quality_articles_per_capita  \n",
       "14                      3.498350e-07  \n",
       "8                       2.877698e-07  \n",
       "0                       2.459016e-07  \n",
       "1                       1.949318e-07  \n",
       "5                       1.389932e-07  \n",
       "13                      1.171303e-07  \n",
       "17                      1.158301e-07  \n",
       "16                      9.140149e-08  \n",
       "9                       9.009009e-08  \n",
       "2                       6.218905e-08  \n",
       "7                       5.861665e-08  \n",
       "10                      4.470588e-08  \n",
       "12                      4.431838e-08  \n",
       "6                       3.964321e-08  \n",
       "4                       3.535038e-08  \n",
       "15                      2.953874e-08  \n",
       "11                      1.034891e-08  \n",
       "3                       1.919754e-09  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute the total coverage for high-quality articles for a geographical region\n",
    "regions_high_quality_coverage = aggregated_politicians_population_df.groupby('region').agg({'high_quality_articles': 'sum',\n",
    "                                                                                            'population': 'sum'}).reset_index()\n",
    "\n",
    "# Calculate high-quality articles per capita for each region\n",
    "regions_high_quality_coverage['high_quality_articles_per_capita'] = regions_high_quality_coverage['high_quality_articles'] / regions_high_quality_coverage['population']\n",
    "\n",
    "# Sort by high-quality articles per capita in descending order\n",
    "regions_high_quality_coverage_sorted = regions_high_quality_coverage.sort_values(by='high_quality_articles_per_capita', ascending=False)\n",
    "display(regions_high_quality_coverage_sorted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "\n",
    "Similar to what we observed in the last section (2.5)\n",
    "- Northern Europe is ranked 1 for having the highest number of high-quiality articles per person. Relatiove to the population size, we have many high-quality articles here.\n",
    "- In the same way, Oceania and the Caribbean also have high coverage.\n",
    "- Regions like East Asia and South Asia continue to show a low number of high-quality articles per person though they have larger populations. It could indicate that the political discussions are either not that accessible in these areas.\n",
    "- In the similar way, though regions like Eastern Africa and Western Africa, boasts about having a high total number of high-quality articles, their population hinders them to be highly ranked here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We were successful in finally generating the observations, however, we did observe some bias.\n",
    "\n",
    "### 3.1 Bias \n",
    "\n",
    "The observations in Section 2 clearly indicate a bias in how various regions prioritize political topics.\n",
    "\n",
    "The majority of articles analyzed came from English Wikipedia. To mitigate this, I included six additional articles from different languages to help reduce bias related to language. Since English is not the primary language in many Eastern countries, English Wikipedia may lean more towards Western perspectives, leading to a skewed representation of political information.\n",
    "\n",
    "Before I began my analysis, I expected to find a disproportionate distribution of articles produced by wealthier countries compared to others. I suspected that they would have more articles, and to a certain extent, I was right. However, it was only when we examined the per-capita comparisons that we encountered a different set of bias complications.\n",
    "\n",
    "Another issue is the \"data gap.\" If someone relies solely on Wikipedia to analyze political engagement, there’s a significant chance they will overlook many viewpoints and events, as a single platform can never portray 100% of what is happening globally. While Wikipedia can definitely serve as a starting point or be useful in the early stages of a statistical analysis, we must be mindful of its limitations.\n",
    "\n",
    "### 3.2 Solution\n",
    "\n",
    "We could include more data from other language versions of Wikipedia or even from different platforms that focus on political discussions in underrepresented regions, particularly in Eastern countries. This would enhance reliability by reducing the bias that was previously introduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
